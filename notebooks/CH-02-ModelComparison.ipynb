{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Reto 02: Modelos y Capacidades de Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Introducción\n",
    "\n",
    "En este reto, aprenderás sobre las diferentes capacidades de los modelos de Azure OpenAI y cómo elegir el mejor modelo para tu caso de uso.\n",
    "\n",
    "Vas a comparar el modelo GPT-3.5 con el modelo GPT-4 en este desafío. Si no tienes acceso a GPT-4, puedes comparar los modelos legacy si están implementados, o realizar este desafío de manera conceptual para entender cómo elegir el mejor modelo entre los que tienes implementados, así como los que están en el catálogo de modelos.\n",
    "\n",
    "En un mundo donde la disponibilidad y el desarrollo de modelos están en constante cambio, el modelo que comparemos puede cambiar con el tiempo. Pero te animamos a entender los conceptos generales y el material en este desafío porque las técnicas de comparación utilizadas pueden aplicarse a escenarios en los que estés comparando Modelos de Lenguaje Grande.\n",
    "\n",
    "Preguntas que podrás responder al final de este desafío:\n",
    "\n",
    "* ¿Cómo difieren las respuestas de cada modelo?\n",
    "* ¿Cuáles son las formas de evaluar el rendimiento de los modelos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 1. Descripción general sobre cómo encontrar el modelo adecuado para ti\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.1 Familias de Modelos\n",
    "\n",
    "Azure OpenAI proporciona acceso a muchos modelos diferentes, agrupados por familia y capacidad. Una familia de modelos generalmente asocia modelos según su tarea prevista.\n",
    "\n",
    "Las familias de modelos disponibles actualmente a partir del _1 de diciembre de 2023_ en Azure OpenAI incluyen GPT-4, GPT-3.5, Embeddings, DALL-E y Whisper. Consulta este enlace para obtener más información: [Modelos de Azure OpenAI ](https://learn.microsoft.com/es-mx/azure/ai-services/openai/concepts/models)\n",
    "\n",
    "Para GPT-3 y otros modelos retirados en Julio de 2024, consulta [Modelos en desuso del servicio Azure OpenAI](https://learn.microsoft.com/es-mx/azure/ai-services/openai/concepts/legacy-models).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.2 Capacidades del Modelo\n",
    "#### GPT-4\n",
    "GPT-4 puede resolver problemas difíciles con mayor precisión que cualquiera de los modelos anteriores de OpenAI. Al igual que GPT-3.5 Turbo, GPT-4 está optimizado para chat y funciona bien para tareas de completado tradicionales. Usa la API de Chat Completions para usar GPT-4.\n",
    "\n",
    "#### GPT-3.5\n",
    "Los modelos GPT-3.5 pueden entender y generar lenguaje natural o código. El modelo más capaz y rentable de la familia GPT-3.5 es GPT-3.5 Turbo, que ha sido optimizado para chat y también funciona bien para tareas de completado tradicionales. GPT-3.5 Turbo está disponible para usar con la API de Chat Completions. GPT-3.5 Turbo Instruct tiene capacidades similares a text-davinci-003 utilizando la API de Completions en lugar de la API de Chat Completions. Recomendamos usar GPT-3.5 Turbo y GPT-3.5 Turbo Instruct en vez de los modelos en desuso GPT-3.5 y GPT-3.\n",
    "\n",
    "`gpt-35-turbo`\n",
    "\n",
    "`gpt-35-turbo-16k`\n",
    "\n",
    "`gpt-35-turbo-instruct`\n",
    "\n",
    "Puedes ver la longitud del contexto de tokens admitida por cada modelo en la [tabla resumen del modelo](https://learn.microsoft.com/es-mx/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability).\n",
    "\n",
    "#### Embeddings \n",
    "Los modelos de embeddings anteriores se han consolidado en un nuevo modelo de reemplazo:\n",
    "\n",
    "`text-embedding-ada-002`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "\n",
    "[Modelos de Azure OpenAI](https://learn.microsoft.com/es-mx/azure/cognitive-services/openai/concepts/models)  \n",
    "\n",
    "\n",
    "| Modelos | Descripción |\n",
    "| --- | --- |\n",
    "| GPT-4 | Un conjunto de modelos que mejoran GPT-3.5 y pueden entender y generar lenguaje natural y código. | \n",
    "| GPT-3.5 | Un conjunto de modelos que mejoran GPT-3 y pueden entender y generar lenguaje natural y código. | \n",
    "| Embeddings | Un conjunto de modelos que pueden convertir texto en forma de vector numérico para facilitar la similitud de texto. | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.3 Detalles de Precios\n",
    "\n",
    "Para obtener la información más actualizada, consulta la [página de precios](https://azure.microsoft.com/es-mx/pricing/details/cognitive-services/openai-service/) de Azure OpenAI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.4 Cuotas y Límites\n",
    "\n",
    "*Los límites que se indican a continuación están sujetos a cambios. Anticipamos que necesitarás límites más altos a medida que avances hacia producción y tu solución escale. Cuando conozcas los requisitos de tu solución, comunícate solicitando un aumento de cuota aquí: [Solicitud de aumento de cuota](https://aka.ms/oai/quotaincrease).\n",
    "\n",
    "|Nombre del Límite\t|Valor del Límite|\n",
    "|---|---|\n",
    "|Recursos de OpenAI por región por suscripción de Azure|\t30|\n",
    "| Límites de cuota predeterminados de DALL-E 2| 2 solicitudes concurrentes |\n",
    "| Límites de cuota predeterminados de DALL-E 3  | 2 unidades de capacidad (6 solicitudes por minuto)|\n",
    "|Máximo de tokens de prompt por solicitud| Varía según el modelo, consulta [Modelos del Servicio Azure OpenAI](https://learn.microsoft.com/es-mx/azure/ai-services/openai/concepts/models) |\n",
    "|Máximo de implementaciones de modelos ajustados|5|\n",
    "|Número total de trabajos de entrenamiento por recurso|\t100|\n",
    "|Máximo de trabajos de entrenamiento en ejecución simultáneos por recurso|\t1|\n",
    "|Máximo de trabajos de entrenamiento en cola\t|20|\n",
    "|Máximo de archivos por recurso\t|30|\n",
    "|Tamaño total de todos los archivos por recurso\t|1 GB|\n",
    "|Tiempo máximo de trabajo de entrenamiento (el trabajo fallará si se excede)\t|720 horas|\n",
    "|Tamaño máximo de trabajo de entrenamiento (tokens en el archivo de entrenamiento) x (# de épocas)\t|2 mil millones|\n",
    "|Tamaño máximo de todos los archivos por carga (Azure OpenAI en tus datos)\t|16 MB|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.5 Selección del Modelo\n",
    "\n",
    "Aquí tienes algunas recomendaciones generales sobre los escenarios adecuados que tienden a diferenciar los modelos. Ten en cuenta que estas no son reglas estrictas y, a menudo, la experimentación y la evaluación comparativa son importantes para tomar la mejor decisión para tu solución.\n",
    "\n",
    "|Modelo|Casos de Uso|\n",
    "|---|---|\n",
    "|GPT-3.5| Rendimiento de aplicaciones más rápido/económico; <br/>Mayor cuota asignada de forma predeterminada |\n",
    "|GPT-4| Se necesita un razonamiento o procesamiento lógico más avanzado; <br/> Una ventana de 32k tokens es absolutamente necesaria; <br/>Se necesita dominio de varios idiomas; <br/>No hay un requisito estricto de baja latencia|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.6 Prácticas Recomendadas para la Selección de Modelos\n",
    "Recomendamos a los usuarios que comiencen con GPT-3.5 Turbo si se identifican con el caso de uso mencionado anteriormente y que pasen a GPT-4 si es necesario.\n",
    "\n",
    "Una vez que tenga un prototipo en funcionamiento, podrá optimizar la elección de su modelo con el mejor equilibrio entre latencia y rendimiento para su aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 2. Comencemos con la Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Si aún no tienes instalados los paquetes OpenAI, Python-dotenv, plotly o scikit-learn en tu equipo, las siguientes celdas los instalarán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1685909662455
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Configura tu entorno para acceder a tus claves de OpenAI. Consulta tu recurso de OpenAI en el Portal de Azure para recuperar la información sobre tu punto de conexión y las claves de OpenAI.\n",
    "\n",
    "Por razones de seguridad, almacena tu información sensible en un archivo .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686331271142
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "chat_model=os.getenv(\"CHAT_MODEL_NAME\")\n",
    "chat_model2=os.getenv(\"CHAT_MODEL_NAME2\")\n",
    "text_model=os.getenv(\"EMBEDDING_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2.0 Funciones Auxiliares\n",
    "A lo largo de este curso, utilizaremos los modelos `gpt-3.5-turbo` y `gpt-4` de OpenAI y el [punto de conexión de chat completions](https://platform.openai.com/docs/guides/chat). \n",
    "\n",
    "Esta función auxiliar hará que sea más fácil usar prompts y ver las salidas generadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**timer wrapper** nos ayuda a monitorear y comparar la latencia de cada modelo.\n",
    "\n",
    "**get_chat_completion** ayuda a crear la respuesta de OpenAI utilizando el modelo de chat de tu elección. \n",
    "\n",
    "**get_completion_from_messages** ayuda a crear la respuesta de OpenAI utilizando el modelo de chat de tu elección, habilitando el historial de chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686334202300
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        run_time = end_time - start_time\n",
    "        print(\"Finished {} in {} secs\".format(repr(func.__name__), round(run_time, 3)))\n",
    "        return value[0], value[1], round(run_time, 3)\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686334262004
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def get_chat_completion(prompt, model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens = 200,\n",
    "        top_p = 1.0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"],response['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686334263077
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def get_completion_from_messages(messages, model, temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    #print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"],response['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2.1 Resumir Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686334268062
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model_pricing = pd.DataFrame(columns=['model', 'price', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686334278657
    }
   },
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "The Olympic Games Tokyo 2020 reached a global broadcast audience of 3.05 billion people, according to independent research conducted on behalf of the International Olympic Committee (IOC). Official coverage on Olympic broadcast partners\\' digital platforms alone generated 28 billion video views in total – representing a 139 per cent increase compared with the Olympic Games Rio 2016 and underlining the changing media landscape and Tokyo 2020\\'s designation as the first streaming Games and the most watched Olympic Games ever on digital platforms.Sony and Panasonic partnered with NHK to develop broadcasting standards for 8K resolution television, with a goal to release 8K television sets in time for the 2020 Summer Olympics. In early 2019, Italian broadcaster RAI announced its intention to deploy 8K broadcasting for the Games. NHK broadcast the opening and closing ceremonies, and coverage of selected events in 8K. Telecom company NTT Docomo signed a deal with Finland\\'s Nokia to provide 5G-ready baseband networks in Japan in time for the Games.The Tokyo Olympics were broadcast in the United States by NBCUniversal networks, as part of a US$4.38 billion agreement that began at the 2014 Winter Olympics in Sochi. The United States Olympic & Paralympic Committee asserted that a \"right of abatement\" clause in the contract was triggered by the delay of the Games to 2021, requiring the IOC to \"negotiate in good faith an equitable reduction in the applicable broadcast rights payments\" by NBC, which remains one of IOC\\'s biggest revenue streams. According to NBCUniversal CEO Jeff Shell, the Tokyo games could be the most profitable Olympics in NBC\\'s history. The Tokyo games were NBC\\'s first Olympics broadcast under current president Susan Rosner Rovner.In Europe, this was the first Summer Olympics under the IOC\\'s exclusive pan-European rights deal with Eurosport, which began at the 2018 Winter Olympics and is contracted to run through 2024. The rights for the 2020 Summer Olympics covered almost all of Europe; a pre-existing deal with a marketer excludes Russia. Eurosport planned to sub-license coverage to free-to-air networks in each territory, and other channels owned by Discovery, Inc. subsidiaries. In the United Kingdom, these were set to be the last Games with rights owned primarily by the BBC, although as a condition of a sub-licensing agreement due to carry into the 2022 and 2024 Games, Eurosport holds exclusive pay television rights. In France, these were the last Games whose rights are primarily owned by France Télévisions. Eurosport debuted as pay television rightsholder, after Canal+ elected to sell its pay television rights as a cost-saving measure.In Canada, the 2020 Games were shown on CBC/Radio-Canada platforms, Sportsnet, TSN and TLN. In Australia, they were aired by Seven Network. In the Indian subcontinent, they were aired by Sony Pictures Networks India (SPN).\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "gpt35_response, gpt35_price, gpt35_time = get_chat_completion(prompt, model=chat_model)\n",
    "gpt4_response, gpt4_price, gpt4_time = get_chat_completion(prompt, model=chat_model2)\n",
    "\n",
    "print(f\"GPT-3.5 Response: {gpt35_response}\\n\")\n",
    "print(f\"GPT-4 Response: {gpt4_response}\\n\")\n",
    "\n",
    "new_rows = pd.DataFrame([{'model': 'gpt3.5', 'price': gpt35_price, 'time': gpt35_time},\n",
    "                         {'model': 'gpt4', 'price': gpt4_price, 'time': gpt4_time}])\n",
    "pricing = pd.concat([model_pricing, new_rows], ignore_index=True)\n",
    "print(pricing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #1 del Estudiante:\n",
    "Con las tácticas aprendidas en el primer desafío, edita el prompt para obtener una respuesta más concisa del asistente. ¿Encuentras alguna diferencia en el resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Edita el prompt para obtener una respuesta más concisa del asistente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2.2 Resumir Texto para una audiencia específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686332538379
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks into a single sentence for 7-year-old to understand.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "gpt35_response, gpt35_price, gpt35_time = get_chat_completion(prompt, model=chat_model)\n",
    "gpt4_response, gpt4_price, gpt4_time = get_chat_completion(prompt, model=chat_model2)\n",
    "print(f\"GPT-3.5 Response: {gpt35_response}\\n\")\n",
    "print(f\"GPT-4 Response: {gpt4_response}\\n\")\n",
    "\n",
    "new_rows = pd.DataFrame([{'model': 'gpt3.5', 'price': gpt35_price, 'time': gpt35_time},\n",
    "                                       {'model': 'gpt4', 'price': gpt4_price, 'time': gpt4_time}])\n",
    "pricing = pd.concat([model_pricing, new_rows], ignore_index=True)\n",
    "print(pricing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #2 del Estudiante:\n",
    "Edita el prompt para resumir el texto en un título llamativo para un periódico. Compara diferentes resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Edita el prompt para resumir el texto en un título llamativo para un periódico. Compara diferentes resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2.3 Resumir causa y efecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686332587257
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Summarize the major event's cause and effect for the text delimited by triple backticks into a single sentence less than 50 words.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "gpt35_response, gpt35_price, gpt35_time = get_chat_completion(prompt, model=chat_model)\n",
    "gpt4_response, gpt4_price, gpt4_time = get_chat_completion(prompt, model=chat_model2)\n",
    "print(f\"GPT-3.5 Response: {gpt35_response}\\n\")\n",
    "print(f\"GPT-4 Response: {gpt4_response}\\n\")\n",
    "\n",
    "new_rows = pd.DataFrame([{'model': 'gpt3.5', 'price': gpt35_price, 'time': gpt35_time},\n",
    "                                       {'model': 'gpt4', 'price': gpt4_price, 'time': gpt4_time}])\n",
    "pricing = pd.concat([model_pricing, new_rows], ignore_index=True)\n",
    "print(pricing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #3 del Estudiante: Comparación de Modelos\n",
    "Utiliza la tabla de comparación de modelos para resumir brevemente tus hallazgos después de comparar la salida y el tiempo tomado por diferentes modelos. Por ejemplo: GPT-4: Rendimiento (+++), tiempo (+). También puedes aprovechar otros paquetes de Python para visualizar tus hallazgos.\n",
    "\n",
    "|Modelo| Rendimiento  |Tiempo|\n",
    "|---|---|---|\n",
    "|GPT-3.5|||\n",
    "|GPT-4|||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    " #### Tarea #4 del Estudiante: Clasificación de Texto\n",
    " Edita el prompt para hacer que los modelos generen categorías clave de temas para el texto. Compara el rendimiento de diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Edita el prompt para hacer que los modelos generen categorías clave de temas para el texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #5 del Estudiante:\n",
    "Edita el prompt para que los modelos generen resultados más precisos. Compara el rendimiento de diferentes modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Edita el prompt para que los modelos generen resultados más precisos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #6 del Estudiante: Comparación de Modelos\n",
    "\n",
    "Escribe código para crear dos gráficos de barras comparando el **precio** y el **tiempo de completado** entre los modelos. Recomendamos utilizar la biblioteca `matplotlib.pyplot` para hacer visualizaciones.\n",
    "\n",
    "Instrucciones para el completado:\n",
    "\n",
    "* Utiliza el dataframe `model_pricing` para calcular los promedios de precio y tiempo para cada modelo.\n",
    "* Produce el gráfico de barras con un monto de moneda. Ten en cuenta que la columna `price` en el dataframe `model_pricing` está en la unidad de tokens. Consulta la [página de precios de Azure OpenAI] (https://azure.microsoft.com/es-mx/pricing/details/cognitive-services/openai-service/) para convertir las unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" TAREA DEL ESTUDIANTE \"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### 1. Gráfica de barras para comparar el precio\n",
    "\n",
    "\n",
    "### 2. Gráfica de barras para comparar el tiempo de completado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2.4 Generar Apodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #7 del Estudiante:\n",
    "Utiliza diferentes modelos para crear apodos para jugadores a partir de palabras de ejemplo. Compara el rendimiento de diferentes modelos. (Puedes establecer el valor de la temperatura alto para aumentar la aleatoriedad y obtener respuestas más innovadoras.)\n",
    "\n",
    "Player description: The champion of Men's 100 metre freestyle swimming. Seed words: fast, strong, talented.Nick names: Swimming Genius, Dark Horse, 100-Metre-Freestyle Killer\n",
    "\n",
    "Player description: The champion of Women Figure Skating. Seed words: elegant, talented, soft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1685916265011
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Escribe tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Comparación de Modelos\n",
    "|Modelo| Rendimiento  |Tiempo|Tokens|Precio |\n",
    "|---|---|---|---|---|\n",
    "|GPT-3.5|||||\n",
    "|GPT-4||||||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2.5 Embeddings\n",
    "Esta sección se centra en cómo recuperar embeddings utilizando diferentes modelos de embeddings y encontrar similitudes entre documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Tarea #8 del Estudiante:\n",
    "Compara los resúmenes de dos juegos de natación en los Juegos Olímpicos de Verano de 2020 utilizando los datos proporcionados a continuación.\n",
    "\n",
    "Observa si hay diferencias al utilizar diferentes modelos de embeddings para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686117865502
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686117698204
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "game_summary = [\n",
    "    \"The mixed 100 metre medley relay event at the 2020 Summer Olympics was held in 2021 at the Tokyo Aquatics Centre. These Games marked the first time to feature a mixed-gender swimming event in the program. Each 4-person team features two male and two female swimmers in no particular order. The medals for the competition were presented by Kirsty Coventry IOC Executive Board Member, Zimbabwe; Olympian, 2 Gold Medals, 4 Silver Medals, 1 Bronze Medal, and the medalists bouquets were presented by Errol Clarke, FINA Bureau Member; Barbados.\",\n",
    "    \"The men's 200 metre breaststroke event at the 2020 Summer Olympics was held from 27 to 29 July 2021 at the Tokyo Aquatics Centre. It was the event's twenty-sixth consecutive appearance, having been held at every edition since 1908.\"\n",
    "]\n",
    "\n",
    "game_highlight = [\n",
    "    'The 2020 Summer Olympics featured the first ever mixed-gender swimming event, the 100 metre medley relay. Medals were presented by Kirsty Coventry and bouquets by Errol Clarke.',\n",
    "    \"The men's 200 metre breaststroke event was held at the 2020 Summer Olympics in Tokyo, making it the event's 26th consecutive appearance since 1908.\"\n",
    "]\n",
    "\n",
    "olympics_game_df = pd.DataFrame({\"summary\":game_summary, \"qualification\":game_highlight})\n",
    "\n",
    "olympics_game_df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686117707487
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "@timer\n",
    "def get_embedding(text, model=text_model):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text,\n",
    "        engine=model\n",
    "    )\n",
    "    return response[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1686117710151
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "article1_embedding = get_embedding(text=olympics_game_df.summary.iloc[0])\n",
    "article2_embedding = get_embedding(text=olympics_game_df.summary.iloc[1])\n",
    "print(cosine_similarity(article1_embedding, article2_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Conclusión\n",
    "\n",
    "En este Desafío, aprendiste sobre técnicas para comparar diferentes tipos de modelos de Azure OpenAI. Aunque recomendamos usar GPT-3.5 y GPT-4, estos métodos también se pueden aplicar a otros modelos para determinar la mejor solución para tu caso de uso. En el Desafío 3, aprenderás cómo trabajar con mayores cantidades de datos."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
